# System Architecture Overview

This backend system is designed as a set of modular components (“managers”) that work together to perform real-time person detection and track walking direction on a Raspberry Pi 5. The architecture separates concerns into independent modules to improve maintainability and optimize for the Pi’s limited resources. Key components include:

- CameraManager: Handles video capture from the camera, streaming frames into the system.
- DetectionManager: Runs YOLOv8 person detection on incoming frames. It adapts the processing rate (1 FPS when idle, ~5–6 FPS when a person is present) and uses a lightweight tracking method to determine the person’s walking direction.
- DashboardManager: Collects analytics and metrics (e.g. counts of detections, walking direction statistics). It prepares data for dashboards or status pages.
- APIManager: Exposes a RESTful API (using Flask or FastAPI) to interact with the system. It provides endpoints for status, metrics, and basic testing pages.
- DatabaseManager: Manages a SQLite database for persistent storage (e.g. logging detection events, configurations).
- ResourceProvider: Provides configuration management and structured logging setup for all modules (centralizing configuration values and logger instances).

**Interaction Flow:** The CameraManager continuously captures video frames (without dropping frames) and makes them available to the DetectionManager (via a thread-safe queue or shared buffer). The DetectionManager processes frames at the appropriate rate: it performs YOLOv8 inference to detect people. When no person is detected, it operates in idle mode (processing one frame per second). Once a person is detected, it switches to active mode and processes ~5–6 frames per second to closely track the person’s movement. During active mode, the DetectionManager uses an efficient tracking approach (e.g. simple centroid tracking or optical flow between consecutive frames) to determine the direction the person is moving (e.g. left-to-right or right-to-left across the frame). This approach balances accuracy with the Pi’s performance constraints, avoiding heavy algorithms unless necessary. If multiple people need to be tracked, the system can be extended to use a multi-object tracker like Deep SORT (which combines YOLO detections with a lightweight Kalman Filter tracker) – but by default a simpler tracking method is used for efficiency. 

**Concurrency Model:**  To ensure a smooth live video feed without frame drops, the system uses multithreading to parallelize camera capture and detection:
- The CameraManager runs in its own thread, continually grabbing frames from the camera as fast as possible (or at a fixed camera FPS). It places frames into a shared queue (with a maximum size of 1 or 2) so that the latest frame is always available to the DetectionManager.
- The DetectionManager runs in a separate thread, pulling frames from the queue. If the DetectionManager falls behind, the queue mechanism ensures it always processes the most recent frame (discarding older frames) to avoid lag. This decoupling via a buffer prevents the camera feed from pausing during intensive detection periods.
- The APIManager (Flask/FastAPI server) runs on the main thread (or its own process if using an ASGI server) and handles incoming requests concurrently. It can safely query the latest status from DetectionManager or DashboardManager without interrupting the video processing threads.
- Communication between threads is done through thread-safe structures and shared state protected by locks where necessary. For example, the DetectionManager can update a shared variable (with a lock) indicating “person present” or the latest direction, which the APIManager reads to serve client requests. Alternatively, the DatabaseManager is used to log events which the API can read.

By using threads (and relying on Python’s GIL release during I/O and computation in C libraries like OpenCV/YOLO), we achieve concurrency without the overhead of inter-process communication. If CPU-bound processing becomes a bottleneck, the design can be scaled to multiprocessing (e.g., running the DetectionManager in a separate process and communicating via multiprocessing Queues or a socket). However, on the Pi 5, the multithreading approach with careful synchronization should suffice and is simpler to implement. Scalability: This modular design makes it easy to swap or scale components. For instance, the YOLOv8 model could be replaced with a more efficient model or run on a Coral TPU in the future. Each manager can be extended or replaced independently (e.g., using FastAPI instead of Flask in APIManager, or adding more cameras with additional CameraManagers). The system remains efficient by doing minimal work when idle and scaling up intelligently when activity is detected.