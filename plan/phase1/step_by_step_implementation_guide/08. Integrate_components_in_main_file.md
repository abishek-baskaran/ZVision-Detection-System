- Create main.py at the project root. This script will tie everything together:
```
from managers.resource_provider import ResourceProvider
from managers.database_manager import DatabaseManager
from managers.dashboard_manager import DashboardManager
from managers.camera_manager import CameraManager
from managers.detection_manager import DetectionManager
from managers.api_manager import APIManager

def main():
    # Initialize core providers
    resource = ResourceProvider("config.yaml")
    db = DatabaseManager(resource)
    dashboard = DashboardManager(resource)
    # Initialize Camera and Detection managers
    camera = CameraManager(resource)
    detection = DetectionManager(resource, camera, dashboard, db)
    # Initialize API manager
    api = APIManager(resource, camera, detection, dashboard, db)

    # Start background threads
    camera.start()
    detection.start()
    # Run API server (this will block this thread until program exit)
    try:
        api.run()
    except KeyboardInterrupt:
        print("Shutting down...")
    finally:
        # Cleanup: stop threads and close DB
        detection.stop()
        camera.stop()
        db.close()

if __name__ == "__main__":
    main()
```
    - This orchestrator does the following: loads config and logging, starts the database and dashboard managers, then camera and detection. It finally runs the API server. The try/except ensures that if you press Ctrl+C to stop the program, it attempts to shut down gracefully (stopping threads and closing the database).
    - Note that when api.run() is called (Flask), the camera and detection threads are already running in background. The Flask server will handle incoming HTTP requests asynchronously. The detection logic continues to run concurrently thanks to the threads.
- Run python main.py on the Raspberry Pi. Watch the logs (tail -f logs/app.log) and test the system:
    - Open a browser to http://<Pi's IP>:5000/ to load the test page. You should see the status updating every second.
    - When no one is in front of the camera, the status should indicate no person present. The detection thread is only processing one frame a second (check CPU usage – it should be low).
    - When a person comes into view, within a second the system should detect them. The status should update (“person_present: True”), and you should see in logs that it switched to active mode. Now it will start processing ~5 FPS; you might see CPU usage spike due to YOLO model running. The direction field might remain null or None until enough frames have been processed to determine movement.
    - After the person moves, the status should show a direction (“left” or “right”) once determined. This might take a few frames of movement. If the person stays still, direction might remain None or not change – that’s expected.
    - When the person leaves the frame, after about a second of no detections, the system should mark person_present as False and revert to idle mode.
    - Use the /events endpoint (e.g., navigate to http://<Pi IP>:5000/events) to see the logged events. You should see entries like person_appeared, direction, person_disappeared with timestamps and data. This confirms the DatabaseManager is recording information.
- If anything is not working as expected (for example, if frames aren’t being processed timely or detection is inconsistent), use the logs to debug. Perhaps adjust the idle_interval or active_interval if needed, or tweak the detection confidence threshold to balance between false negatives and false positives.
- Once verified, you have a complete working backend.