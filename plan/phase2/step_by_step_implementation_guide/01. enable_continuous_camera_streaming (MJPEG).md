To provide a live camera feed in the dashboard without heavy client-side code, we’ll add an MJPEG streaming endpoint. This will push a continuous stream of JPEG images over HTTP, which the browser can display as a video.
- Extend APIManager with a /video_feed route: In the APIManager._register_routes() function, create a new Flask route that returns a streaming response. Use OpenCV to grab frames from CameraManager and encode them as JPEG in a loop. For example:

```
from flask import Response

@self.app.route('/video_feed')
def video_feed():
    # Generator function to yield frames in MJPEG format
    def gen_frames():
        while True:
            frame = self.camera_manager.get_latest_frame()
            if frame is None:
                continue  # no frame available yet
            success, buffer = cv2.imencode('.jpg', frame)
            if not success:
                continue
            # Convert to bytes and yield as an MJPEG frame
            frame_bytes = buffer.tobytes()
            yield (b'--frame\r\n'
                   b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
    # Return a streaming response with the correct MIME type
    return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')
```
This uses a boundary --frame to separate JPEG images. The browser’s <img> tag can consume this as a video stream​. We leverage the existing CameraManager (which is capturing frames at 30 FPS by default) – the stream will always send the latest frame available.

- Update the Frontend to use the stream: In the HTML page, replace the static image logic with a direct stream. For example, set the src of the camera <img> to /video_feed on page load:
```
<img id="camera-feed" src="/video_feed" alt="Live camera feed">
```
This way, the browser will continuously load frames. You can remove or reduce the usage of the updateFrame() JavaScript polling function, as the <img> will update on its own. This significantly improves the real-time feel of the video feed. The MJPEG stream is simpler and more CPU-friendly on the Pi than WebRTC, and it’s widely supported.

- Consider Frame Rate & Resource Use: The Pi 5 should handle streaming 640x480 JPEGs, but to avoid overloading, you may throttle the loop in gen_frames() if needed (e.g., a short time.sleep(0.05) to cap at ~20 FPS, or use camera’s FPS). The camera thread already drops old frames (queue size 1), so we always send the newest frame and skip duplicates if the client lags behind. This ensures the video stream doesn’t block detection – each yields reads whatever frame is available and goes on.

- RTSP Camera Support: Modify CameraManager to handle an IP camera stream in the future:
    - In CameraManager.__init__, if the configured device_id is a string (e.g. an RTSP URL), use cv2.VideoCapture(device_id) with that URL. OpenCV supports RTSP links, so this may be as simple as reading a config field like camera.url or detecting device_id type.
    - Test with a sample RTSP source when available. The rest of the system (frame queue, streaming endpoint) remains the same. Keep in mind an IP camera may introduce latency; adjust frame handling if necessary (perhaps increase queue size or handle disconnects).
    
By completing this step, the frontend will have a live video feed from the camera that updates in real time, independent of the detection loop.