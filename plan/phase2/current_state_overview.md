- **Camera & Detection:** The project already uses a separate camera capture thread (CameraManager) and a YOLOv8-based detection thread (DetectionManager). The detection logic adapts its frame processing rate: ~1 FPS when idle (no person) and ~5 FPS when a person is detected – this meets the target algorithm behavior. Both threads run concurrently, so detection doesn’t block camera capture.

- **Database & Metrics:** A SQLite database (DatabaseManager) is integrated, logging events (detection start/end, directions) and storing settings. The DashboardManager keeps in-memory counts (total detections, direction counts) and timestamps for quick access. It increments a footfall count (detection_count) each time a person is detected and tracks the last detection time and last direction.

- **API Endpoints:** A Flask-based APIManager provides endpoints to retrieve status (/api/status), recent events (/api/events and /api/detections/recent), metrics (/api/metrics for total and hourly stats), the latest frame (/api/frame/current returns a base64 JPEG), and static test page (/test or /). These allow the frontend to pull data and images. However, there are no endpoints yet to start/stop detection or to stream video continuously.

- **Frontend (test_page.html):** The current HTML page displays the camera feed image and stats by periodically polling the REST API. JavaScript uses fetch() to update status, frame, and metrics every 5 seconds. It shows whether a person is detected, movement direction, footfall (total detections), and last detection time. A “Refresh” button triggers an on-demand update. There is no control to toggle the detection on/off, and the camera feed is updated via periodic snapshots rather than a true live stream.